# **Machine Learning**

## üìå Como a m√°quina aprende?

> **Dados ‚Üí Processamento ‚Üí Modelo**

---

## üìä Tipos de dados

Em Machine Learning, os dados mais comuns s√£o **tabulares (tabelas)**.  
Essas tabelas possuem tr√™s elementos principais:

- **Atributos:** colunas dos dados tabulares.  
- **Inst√¢ncias:** linhas (exceto o cabe√ßalho).  
- **Classes:** objetivo ou r√≥tulo que se deseja prever.  

---

## üß© Tarefas em Machine Learning

| **Classifica√ß√£o** | **Regress√£o** | **Agrupamento** | **Regras de Associa√ß√£o** |
| ----------------- | ------------- | ---------------- | ------------------------- |
| Predizer um atributo especial chamado ‚Äúclasse‚Äù. | Prever valores num√©ricos cont√≠nuos. | Agrupar dados com base em caracter√≠sticas matem√°ticas. | Identificar rela√ß√µes frequentes entre itens de um conjunto. |
| Supervisionado | Supervisionado | N√£o supervisionado | Supervisionado ou n√£o supervisionado |

---

## üìê Medindo o desempenho do modelo

- **Treino:** algoritmo processa os dados e gera um modelo.  
- **Valida√ß√£o:** dados usados para ajuste fino do modelo.  
- **Teste:** dados usados para avaliar a performance final.  

---

## ‚öôÔ∏è T√©cnicas de treino

- **Hold-out:** separa 70% dos dados para treino e 30% para teste.  
- **Valida√ß√£o Cruzada (k-fold):** divide os dados em *k* subconjuntos; cada subconjunto √© usado como teste uma vez.  
- **Leave-one-out:** varia√ß√£o da valida√ß√£o cruzada, mas deixa apenas **1 inst√¢ncia** de fora por vez.  
- **Subamostragem:** semelhante ao hold-out, mas repetido v√°rias vezes com amostras aleat√≥rias.  

---

## üìè Generaliza√ß√£o x Overfitting x Underfitting

- **Generaliza√ß√£o (ideal):** bom desempenho tanto em treino quanto em produ√ß√£o.  
- **Overfitting (superajuste):** modelo aprende *demais* os dados de treino e n√£o generaliza bem.  
  - **Causas:** poucos dados, modelo complexo, inconsist√™ncia nos dados, m√° sele√ß√£o de atributos, falta de valida√ß√£o cruzada.  
- **Underfitting (subajuste):** modelo muito simples, incapaz de capturar padr√µes.  
  - **Causas:** simplicidade excessiva, poucos dados, m√° sele√ß√£o de atributos, hiperpar√¢metros mal ajustados.  

---

## üßÆ Matriz de Confus√£o (Classifica√ß√£o)

|  | Classe real positiva | Classe real negativa |
| - | ------------------ | --------------------- |
| **Classe prevista positiva** | Verdadeiros Positivos (VP) | Falsos Positivos (FP) |
| **Classe prevista negativa** | Falsos Negativos (FN) | Verdadeiros Negativos (VN) |

### M√©tricas principais

- **Acur√°cia:** `(VP + VN) / (VP + VN + FP + FN)`  
- **Precis√£o:** `VP / (VP + FP)`  
- **Recall (Sensibilidade):** `VP / (VP + FN)`  
- **Especificidade:** `VN / (VN + FP)`  
- **F1 Score:** `2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)`  

---

## üìà ROC e AUC

A **ROC (Receiver Operating Characteristic)** √© uma curva usada para avaliar classificadores bin√°rios.  
A m√©trica **AUC-ROC** mede a √°rea sob essa curva:

- Valor entre **0 e 1**.  
- Quanto mais pr√≥ximo de **1**, melhor a performance do classificador.  

---

## üìè M√©tricas de Erro

Usadas principalmente em **regress√£o** para avaliar a diferen√ßa entre valores previstos e valores reais.

- **ME (Mean Error):**  
  M√©dia simples dos erros. Pode ser positiva ou negativa (depende da escala e dire√ß√£o do erro).  
  `F√≥rmula: ME = (Œ£ (y·µ¢ - ≈∑·µ¢)) / n`

- **MAE (Mean Absolute Error):**  
  M√©dia do valor absoluto dos erros. Mede o erro m√©dio sem considerar sinal. (Depende de escala)
  `F√≥rmula: MAE = (Œ£ |y·µ¢ - ≈∑·µ¢|) / n`

- **MSE (Mean Squared Error):**  
  M√©dia dos erros elevados ao quadrado. Penaliza mais erros grandes.  
  `F√≥rmula: MSE = (Œ£ (y·µ¢ - ≈∑·µ¢)¬≤) / n`

- **RMSE (Root Mean Squared Error):**  
  Raiz quadrada do MSE. Interpreta√ß√£o mais intuitiva porque retorna √† mesma unidade dos dados originais. (n√£o afetado por escala)
  `F√≥rmula: RMSE = ‚àö((Œ£ (y·µ¢ - ≈∑·µ¢)¬≤) / n)`

- **R¬≤ (Coeficiente de Determina√ß√£o):**  
  Mede o quanto o modelo explica da variabilidade dos dados (0 a 1).  
  `F√≥rmula: R¬≤ = 1 - (Œ£ (y·µ¢ - ≈∑·µ¢)¬≤ / Œ£ (y·µ¢ - »≥)¬≤)`

---
