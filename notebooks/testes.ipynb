{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb71b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn spacy requests beautifulsoup4\n",
    "# opcional para pt: python -m spacy download pt_core_news_sm\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# tenta carregar spaCy (opcional). Se não tiver, o código funciona sem ele.\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load(\"pt_core_news_sm\")  # se você fala pt, baixe este modelo\n",
    "    except Exception:\n",
    "        # se o modelo não estiver instalado, usa pipeline em branco (sem sentencizer/lemmatizer)\n",
    "        nlp = None\n",
    "except Exception:\n",
    "    nlp = None\n",
    "\n",
    "# ----------------------------\n",
    "# helpers: coletar e extrair texto\n",
    "# ----------------------------\n",
    "def fetch_url_text(url):\n",
    "    \"\"\"Baixa uma página e retorna o texto dos parágrafos.\"\"\"\n",
    "    r = requests.get(url, timeout=10)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    ps = soup.find_all(\"p\")\n",
    "    text = \"\\n\".join(p.get_text() for p in ps)\n",
    "    return text\n",
    "\n",
    "def load_texts_from_folder(folder):\n",
    "    \"\"\"Carrega .txt de uma pasta e retorna lista de strings.\"\"\"\n",
    "    texts = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "# ----------------------------\n",
    "# pré-processamento e split em sentenças\n",
    "# ----------------------------\n",
    "def split_sentences(text):\n",
    "    \"\"\"Tenta usar spaCy para sentenças; se não, faz split simples.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(text)\n",
    "        return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "    # fallback simples (bom o suficiente pra protótipo)\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [s.strip() for s in sents if s.strip()]\n",
    "\n",
    "def preprocess_sentence(sent):\n",
    "    \"\"\"Limpeza leve; se spaCy estiver disponível, lemmatiza e remove stopwords.\"\"\"\n",
    "    if nlp:\n",
    "        doc = nlp(sent)\n",
    "        toks = [t.lemma_.lower() for t in doc if not t.is_stop and not t.is_punct]\n",
    "        return \" \".join(toks)\n",
    "    # fallback simples\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'\\s+', ' ', sent)\n",
    "    return sent.strip()\n",
    "\n",
    "# ----------------------------\n",
    "# construir índice TF-IDF\n",
    "# ----------------------------\n",
    "class SimpleQAIndex:\n",
    "    def __init__(self):\n",
    "        self.sentences = []\n",
    "        self.sent_orig = []\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.matrix = None\n",
    "\n",
    "    def add_text(self, text):\n",
    "        sents = split_sentences(text)\n",
    "        for s in sents:\n",
    "            proc = preprocess_sentence(s)\n",
    "            if proc:\n",
    "                self.sentences.append(proc)\n",
    "                self.sent_orig.append(s)\n",
    "\n",
    "    def build(self):\n",
    "        if not self.sentences:\n",
    "            raise ValueError(\"Índice vazio. Adicione textos primeiro.\")\n",
    "        self.matrix = self.vectorizer.fit_transform(self.sentences)\n",
    "\n",
    "    def answer(self, question, top_k=3):\n",
    "        q = preprocess_sentence(question)\n",
    "        qv = self.vectorizer.transform([q])\n",
    "        sims = cosine_similarity(qv, self.matrix)[0]\n",
    "        idxs = np.argsort(sims)[::-1][:top_k]\n",
    "        results = []\n",
    "        for i in idxs:\n",
    "            results.append({\"score\": float(sims[i]), \"sentence\": self.sent_orig[i]})\n",
    "        return results\n",
    "\n",
    "# ----------------------------\n",
    "# Exemplo de uso\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    qa = SimpleQAIndex()\n",
    "\n",
    "    # 1) adicionar textos locais\n",
    "    # texts = load_texts_from_folder(\"meus_textos\")\n",
    "    # for t in texts:\n",
    "    #     qa.add_text(t)\n",
    "\n",
    "    # 2) ou baixar uma URL (exemplo)\n",
    "    exemplo_url = \"https://pt.wikipedia.org/wiki/Pizza\"  # só pra teste\n",
    "    txt = fetch_url_text(exemplo_url)\n",
    "    qa.add_text(txt)\n",
    "\n",
    "    # 3) construir o índice (TF-IDF)\n",
    "    qa.build()\n",
    "\n",
    "    # 4) testar perguntas\n",
    "    pergunta = \"Qual a origem da pizza?\"\n",
    "    respostas = qa.answer(pergunta, top_k=2)\n",
    "    for r in respostas:\n",
    "        print(f\"[{r['score']:.3f}] {r['sentence']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
